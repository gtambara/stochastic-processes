{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Processes - class 1/2024 - University of Brasília\n",
    "Computational work 3 - classification\n",
    "\n",
    "Gabriel Tambara Rabelo - 241106461\n",
    "\n",
    "O presente projeto visa organizar um conjunto de dados a ser utilizado para classificação, atribuindo a estes, dados estatísticos, bem como organizar em histogramas os seus valores de cores, conforme realizado nos trabalhos computacionais 1 e 2. Os resultados seguem o modelo apresentado a seguir:\n",
    "\n",
    "expectancy,mode,median,variance,skewness,kurtosis,entropy,class\n",
    "53.891967984934084,16.0,16.0,2366.491050364323,97417.68593562066,12161679.665451163,1.9169438405823693,0\n",
    "80.08158192090394,16.0,48.0,5663.520651358167,289773.10140834015,61596894.36590457,2.3554137854502386,0\n",
    "80.37126177024481,16.0,48.0,6078.010526279875,372971.9596642113,79378789.52637905,2.392316701226323,0\n",
    "\n",
    "h[0],h[1],h[2],h[3],h[4],h[5],h[6],h[7],class\n",
    "58419,11150,9625,13219,13300,450,20,17,0\n",
    "52196,7232,6733,7406,9320,9624,12177,1512,0\n",
    "\n",
    "A seguir, segue o código equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import log2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "img_size = 300\n",
    "classes = ['Alzheimer', 'COVID', 'Brazilian_seeds', 'Brazilian_leaves', 'skin_cancer']\n",
    "class_labels = {0: 'Alzheimer', 1: 'COVID', 2: 'Brazilian_seeds', 3: 'Brazilian_leaves', 4: 'skin_cancer'}\n",
    "data_dir = './image_dataset/'\n",
    "images = []\n",
    "\n",
    "# Control of when to stop showing images and progressing in the processing\n",
    "def waitKey():\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "# Show images\n",
    "def printAll(list, subtitle):\n",
    "    for i in range(len(list)):\n",
    "        cv.imshow(subtitle + str(i), list[i])\n",
    "\n",
    "# Save images in the correct folder\n",
    "def saveAll(list, subtitle, class_label):\n",
    "    for i in range(len(list)):\n",
    "        cv.imwrite(f\"./images/{class_label}/{subtitle}_{i}.jpg\", list[i])\n",
    "\n",
    "def makeHist(image, bins):\n",
    "    hist, bin_edges = np.histogram(image.flatten(), bins=bins, range=(0, 256))\n",
    "    return hist, bin_edges\n",
    "\n",
    "def normalizeHist(hist):\n",
    "    total_pixels = np.sum(hist)\n",
    "    normalized_hist = hist / total_pixels\n",
    "    return normalized_hist\n",
    "\n",
    "def bin_centers(bin_borders):\n",
    "    bin_center_list = (bin_borders[:-1] + bin_borders[1:]) / 2\n",
    "    bin_center_list[-1] = 255 # Ensure the last bin center is 255\n",
    "    return bin_center_list\n",
    "\n",
    "def expectancy(hist, bin_centers):\n",
    "    return np.sum(hist * bin_centers)\n",
    "\n",
    "def median(hist, bin_centers):\n",
    "    cumulative_freq = np.cumsum(hist)\n",
    "    return bin_centers[np.searchsorted(cumulative_freq, 0.5)]\n",
    "\n",
    "def mode(hist, bin_centers):\n",
    "    return bin_centers[np.argmax(hist)]\n",
    "\n",
    "def moment(hist, bin_centers, order, expectancy):\n",
    "    return np.sum(((bin_centers - expectancy) ** order) * hist)\n",
    "\n",
    "def entropy(hist):\n",
    "    epsilon = 1e-10\n",
    "    return -np.sum(hist * np.log2(hist + epsilon))\n",
    "\n",
    "def calculate_statistics(image, bins):\n",
    "    hist, bin_edges = makeHist(image, bins)\n",
    "    normalized_hist = normalizeHist(hist)\n",
    "    centered_bins = bin_centers(bin_edges)\n",
    "\n",
    "    var_exp = expectancy(normalized_hist, centered_bins)\n",
    "    var_median = median(normalized_hist, centered_bins)\n",
    "    var_mode = mode(normalized_hist, centered_bins)\n",
    "    var_variance = moment(normalized_hist, centered_bins, 2, var_exp)\n",
    "    var_skewness = moment(normalized_hist, centered_bins, 3, var_exp)\n",
    "    var_kurtosis = moment(normalized_hist, centered_bins, 4, var_exp)\n",
    "    var_entropy = entropy(normalized_hist)\n",
    "\n",
    "    return hist, var_exp, var_mode, var_median, var_variance, var_skewness, var_kurtosis, var_entropy\n",
    "\n",
    "def process_images_from_folder(folder_path):\n",
    "    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    images = []\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img = cv.imread(os.path.join(folder_path, image_file), cv.IMREAD_GRAYSCALE)\n",
    "        ratio = img_size / img.shape[1]\n",
    "        img_resized = cv.resize(img, (img_size, int(img.shape[0] * ratio)), cv.INTER_AREA)\n",
    "        images.append(img_resized)\n",
    "\n",
    "    return images\n",
    "\n",
    "def save_statistics_to_csv(images, class_label, case1_csv_filename, case2_csv_filename):\n",
    "    with open(case1_csv_filename, mode='a', newline='') as case1_file, open(case2_csv_filename, mode='a', newline='') as case2_file:\n",
    "        case1_writer = csv.writer(case1_file)\n",
    "        case2_writer = csv.writer(case2_file)\n",
    "        \n",
    "        for image in images:\n",
    "            hist, var_exp, var_mode, var_median, var_variance, var_skewness, var_kurtosis, var_entropy = calculate_statistics(image, bins=8)\n",
    "\n",
    "            case_1_data = list(hist) + [class_label]\n",
    "            case_2_data = [var_exp, var_mode, var_median, var_variance, var_skewness, var_kurtosis, var_entropy, class_label]\n",
    "            \n",
    "            case1_writer.writerow(case_1_data)\n",
    "            case2_writer.writerow(case_2_data)\n",
    "\n",
    "# Initialize CSV files with headers\n",
    "case1_csv_filename = 'case1_statistics.csv'\n",
    "case2_csv_filename = 'case2_statistics.csv'\n",
    "\n",
    "with open(case1_csv_filename, mode='w', newline='') as case1_file, open(case2_csv_filename, mode='w', newline='') as case2_file:\n",
    "    case1_writer = csv.writer(case1_file)\n",
    "    case2_writer = csv.writer(case2_file)\n",
    "    \n",
    "    # Write headers\n",
    "    case1_writer.writerow([f'h[{i}]' for i in range(8)] + ['class'])\n",
    "    case2_writer.writerow(['expectancy', 'mode', 'median', 'variance', 'skewness', 'kurtosis', 'entropy', 'class'])\n",
    "\n",
    "# Process each class folder and save statistics\n",
    "for class_id, class_name in enumerate(classes):\n",
    "    folder_path = os.path.join(data_dir, class_name)\n",
    "    images = process_images_from_folder(folder_path)\n",
    "    save_statistics_to_csv(images, class_id, case1_csv_filename, case2_csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
