{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------CASE1--------------------\n",
      "\n",
      "Bayes Confusion Matrix:\n",
      " [[10  0  0  0  0]\n",
      " [ 0  5  0  1  2]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  0  0  2]]\n",
      "Bayes Accuracy per Class:\n",
      " [1.    0.625 1.    0.8   1.   ]\n",
      "Bayes Accuracy: 0.8461538461538461\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "QDA Confusion Matrix:\n",
      " [[10  0  0  0  0]\n",
      " [ 0  5  0  1  2]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  1  0  4  0]\n",
      " [ 0  0  0  0  2]]\n",
      "QDA Accuracy per Class:\n",
      " [1.    0.625 1.    0.8   1.   ]\n",
      "QDA Accuracy: 0.8461538461538461\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "LDA Confusion Matrix:\n",
      " [[10  0  0  0  0]\n",
      " [ 0  7  0  0  1]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  0  0  2]]\n",
      "LDA Accuracy per Class:\n",
      " [1.    0.875 1.    1.    1.   ]\n",
      "LDA Accuracy: 0.9615384615384616\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "--------------------CASE2--------------------\n",
      "\n",
      "Bayes Confusion Matrix:\n",
      " [[7 0 0 0 0]\n",
      " [0 3 0 2 4]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 3 0]\n",
      " [0 0 0 0 3]]\n",
      "Bayes Accuracy per Class:\n",
      " [1.         0.33333333 1.         1.         1.        ]\n",
      "Bayes Accuracy: 0.7692307692307693\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "QDA Confusion Matrix:\n",
      " [[7 0 0 0 0]\n",
      " [0 5 0 1 3]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 3 0]\n",
      " [0 0 0 0 3]]\n",
      "QDA Accuracy per Class:\n",
      " [1.         0.55555556 1.         1.         1.        ]\n",
      "QDA Accuracy: 0.8461538461538461\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "LDA Confusion Matrix:\n",
      " [[6 0 0 0 1]\n",
      " [0 4 0 1 4]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 2 1]\n",
      " [0 0 0 0 3]]\n",
      "LDA Accuracy per Class:\n",
      " [0.85714286 0.44444444 1.         0.66666667 1.        ]\n",
      "LDA Accuracy: 0.7307692307692307\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorge\\AppData\\Local\\Temp\\ipykernel_31108\\243092258.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  posteriors = [np.log(self.priors[cls]) + np.sum(np.log(self._pdf(cls, x))) for cls in self.classes]\n",
      "C:\\Users\\jorge\\AppData\\Local\\Temp\\ipykernel_31108\\243092258.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "  posteriors = [np.log(self.priors[cls]) + np.sum(np.log(self._pdf(cls, x))) for cls in self.classes]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "img_size = 300\n",
    "classes = ['Alzheimer', 'COVID', 'Brazilian_seeds', 'Brazilian_leaves', 'skin_cancer']\n",
    "data_dir = './image_dataset/'\n",
    "case1_csv_filename = 'case1_statistics.csv'\n",
    "case2_csv_filename = 'case2_statistics.csv'\n",
    "reg_param = 1e-5\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        img = cv.imread(os.path.join(folder_path, img_file), cv.IMREAD_GRAYSCALE)\n",
    "        img_resized = cv.resize(img, (img_size, int(img.shape[0] * img_size / img.shape[1])), cv.INTER_AREA)\n",
    "        images.append(img_resized)\n",
    "    return images\n",
    "\n",
    "def calculate_statistics(image, bins=8):\n",
    "    hist, bin_edges = np.histogram(image.flatten(), bins=np.arange(0, 257, 256 // bins))\n",
    "    hist = hist / np.sum(hist)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    var_exp = np.sum(hist * bin_centers)\n",
    "    var_median = bin_centers[np.searchsorted(np.cumsum(hist), 0.5)]\n",
    "    var_mode = bin_centers[np.argmax(hist)]\n",
    "    var_variance = np.sum(((bin_centers - var_exp) ** 2) * hist)\n",
    "    var_skewness = np.sum(((bin_centers - var_exp) ** 3) * hist)\n",
    "    var_kurtosis = np.sum(((bin_centers - var_exp) ** 4) * hist)\n",
    "    var_entropy = -np.sum(hist * np.log2(hist + 1e-27))\n",
    "    return hist, var_exp, var_median, var_mode, var_variance, var_skewness, var_kurtosis, var_entropy\n",
    "\n",
    "def save_statistics_to_csv(images, class_label):\n",
    "    with open(case1_csv_filename, 'a', newline='') as f1, open(case2_csv_filename, 'a', newline='') as f2:\n",
    "        writer1, writer2 = csv.writer(f1), csv.writer(f2)\n",
    "        for image in images:\n",
    "            stats = calculate_statistics(image)\n",
    "            writer1.writerow(list(stats[0]) + [class_label])\n",
    "            writer2.writerow(stats[1:] + (class_label,))\n",
    "\n",
    "def load_data_from_csv(filename):\n",
    "    data, labels = [], []\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header\n",
    "        for row in reader:\n",
    "            if row:\n",
    "                data.append([float(x) for x in row[:-1]])\n",
    "                labels.append(int(row[-1]))\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def train_test_split(data, labels, test_size=0.1):\n",
    "    indices = np.random.permutation(len(data))\n",
    "    split = int(len(data) * (1 - test_size))\n",
    "    train_idx, test_idx = indices[:split], indices[split:]\n",
    "    return data[train_idx], data[test_idx], labels[train_idx], labels[test_idx]\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, num_classes):\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for i in range(len(y_true)):\n",
    "        cm[y_true[i]][y_pred[i]] += 1\n",
    "    return cm\n",
    "\n",
    "def accuracy_per_class(cm):\n",
    "    return np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "def overall_accuracy(cm):\n",
    "    return np.sum(np.diag(cm)) / np.sum(cm)\n",
    "\n",
    "def evaluate_classifier(classifier, X_train, y_train, X_test, y_test, classifier_name):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred, len(classes))\n",
    "    print(f\"{classifier_name} Confusion Matrix:\\n\", cm)\n",
    "    print(f\"{classifier_name} Accuracy per Class:\\n\", accuracy_per_class(cm))\n",
    "    print(f\"{classifier_name} Accuracy:\", overall_accuracy(cm))\n",
    "    print(\"\\n----------------------------------------\\n\")\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {cls: X[y == cls].mean(axis=0) for cls in self.classes}\n",
    "        self.var = {cls: X[y == cls].var(axis=0) + reg_param for cls in self.classes}\n",
    "        self.priors = {cls: len(X[y == cls]) / len(X) for cls in self.classes}\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "\n",
    "    def _predict(self, x):\n",
    "        posteriors = [np.log(self.priors[cls]) + np.sum(np.log(self._pdf(cls, x) + 1e-10)) for cls in self.classes]\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def _pdf(self, cls, x):\n",
    "        mean, var = self.mean[cls], self.var[cls]\n",
    "        return np.exp(- (x - mean) ** 2 / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "class QuadraticDiscriminantAnalysis:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {cls: X[y == cls].mean(axis=0) for cls in self.classes}\n",
    "        self.cov = {cls: np.cov(X[y == cls].T) + np.eye(X.shape[1]) * reg_param for cls in self.classes}\n",
    "        self.priors = {cls: len(X[y == cls]) / len(X) for cls in self.classes}\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "\n",
    "    def _predict(self, x):\n",
    "        discriminants = [self._quadratic_discriminant(cls, x) for cls in self.classes]\n",
    "        return self.classes[np.argmax(discriminants)]\n",
    "\n",
    "    def _quadratic_discriminant(self, cls, x):\n",
    "        mean, cov = self.mean[cls], self.cov[cls]\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "        W = -0.5 * inv_cov\n",
    "        w = inv_cov @ mean\n",
    "        w0 = -0.5 * (mean @ inv_cov @ mean.T) - 0.5 * np.log(np.linalg.det(cov)) + np.log(self.priors[cls])\n",
    "        return x @ W @ x.T + w @ x + w0\n",
    "\n",
    "class LinearDiscriminantAnalysis:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {cls: X[y == cls].mean(axis=0) for cls in self.classes}\n",
    "        self.cov = np.cov(X.T) + np.eye(X.shape[1]) * reg_param\n",
    "        self.inv_cov = np.linalg.inv(self.cov)\n",
    "        self.priors = {cls: len(X[y == cls]) / len(X) for cls in self.classes}\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "\n",
    "    def _predict(self, x):\n",
    "        discriminants = [self._linear_discriminant(cls, x) for cls in self.classes]\n",
    "        return self.classes[np.argmax(discriminants)]\n",
    "\n",
    "    def _linear_discriminant(self, cls, x):\n",
    "        mean = self.mean[cls]\n",
    "        w = self.inv_cov @ mean\n",
    "        w0 = -0.5 * (mean @ self.inv_cov @ mean.T) + np.log(self.priors[cls])\n",
    "        return w @ x + w0\n",
    "\n",
    "# Initialize CSV files\n",
    "with open(case1_csv_filename, 'w', newline='') as f1, open(case2_csv_filename, 'w', newline='') as f2:\n",
    "    writer1, writer2 = csv.writer(f1), csv.writer(f2)\n",
    "    writer1.writerow([f'h[{i}]' for i in range(8)] + ['class'])\n",
    "    writer2.writerow(['expectancy', 'mode', 'median', 'variance', 'skewness', 'kurtosis', 'entropy', 'class'])\n",
    "\n",
    "# Process images and save statistics\n",
    "for class_id, class_name in enumerate(classes):\n",
    "    folder_path = os.path.join(data_dir, class_name)\n",
    "    images = load_images_from_folder(folder_path)\n",
    "    save_statistics_to_csv(images, class_id)\n",
    "\n",
    "# Evaluate CASE 1\n",
    "data_case1, labels_case1 = load_data_from_csv(case1_csv_filename)\n",
    "X_train_case1, X_test_case1, y_train_case1, y_test_case1 = train_test_split(data_case1, labels_case1)\n",
    "scaler = StandardScaler()\n",
    "X_train_case1 = scaler.fit_transform(X_train_case1)\n",
    "X_test_case1 = scaler.transform(X_test_case1)\n",
    "print(\"\\n--------------------CASE1--------------------\\n\")\n",
    "evaluate_classifier(NaiveBayesClassifier(), X_train_case1, y_train_case1, X_test_case1, y_test_case1, \"Bayes\")\n",
    "evaluate_classifier(QuadraticDiscriminantAnalysis(), X_train_case1, y_train_case1, X_test_case1, y_test_case1, \"QDA\")\n",
    "evaluate_classifier(LinearDiscriminantAnalysis(), X_train_case1, y_train_case1, X_test_case1, y_test_case1, \"LDA\")\n",
    "\n",
    "# Evaluate CASE 2\n",
    "data_case2, labels_case2 = load_data_from_csv(case2_csv_filename)\n",
    "X_train_case2, X_test_case2, y_train_case2, y_test_case2 = train_test_split(data_case2, labels_case2)\n",
    "X_train_case2 = scaler.fit_transform(X_train_case2)\n",
    "X_test_case2 = scaler.transform(X_test_case2)\n",
    "print(\"\\n--------------------CASE2--------------------\\n\")\n",
    "evaluate_classifier(NaiveBayesClassifier(), X_train_case2, y_train_case2, X_test_case2, y_test_case2, \"Bayes\")\n",
    "evaluate_classifier(QuadraticDiscriminantAnalysis(), X_train_case2, y_train_case2, X_test_case2, y_test_case2, \"QDA\")\n",
    "evaluate_classifier(LinearDiscriminantAnalysis(), X_train_case2, y_train_case2, X_test_case2, y_test_case2, \"LDA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
